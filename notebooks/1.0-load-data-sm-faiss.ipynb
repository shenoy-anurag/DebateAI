{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyPacked has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type SwigPyObject has no __module__ attribute\n",
      "<frozen importlib._bootstrap>:488: DeprecationWarning: builtin type swigvarlink has no __module__ attribute\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import faiss\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "\n",
    "UPLOAD_DIR = \"uploads\"\n",
    "\n",
    "UPLOAD_PATH = os.path.join(DATA_DIR, UPLOAD_DIR)\n",
    "\n",
    "os.makedirs(UPLOAD_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file_path):\n",
    "    docs = []\n",
    "\n",
    "    file_name = file_path.rsplit('/', 1)[1]\n",
    "    try:\n",
    "        print(f\"üîç Processing file: {file_path}\")\n",
    "\n",
    "        if file_name.endswith(\".pdf\"):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "        elif file_name.endswith(\".txt\"):\n",
    "            loader = TextLoader(file_path, encoding=\"utf-8\")\n",
    "        elif file_name.endswith(\".json\"):\n",
    "            # loader = JSONLoader(file_path, jq_schema='{question: .[].question, answer: .[].answer}')\n",
    "            loader = JSONLoader(file_path, jq_schema='.[].answer')\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Skipping unsupported file: {file_name}\")\n",
    "            return\n",
    "\n",
    "        loaded_docs = loader.load()\n",
    "        print(f\"‚úÖ Successfully loaded {file_name}\")\n",
    "\n",
    "        docs.extend(loaded_docs)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading {file_name}: {str(e)}\")\n",
    "\n",
    "    if not docs:\n",
    "        print(\"‚ùå No valid documents found!\")\n",
    "        return\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Processing file: ../data/solar-system.json\n",
      "‚úÖ Successfully loaded solar-system.json\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_DIR, 'solar-system.json')\n",
    "docs = process_files(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 1}, page_content='The reddish color is from the rocks that contain iron.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 2}, page_content='The moon casts a shadow on the Earth.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 3}, page_content='It is Uranus.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 4}, page_content='There are 7 large groups.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 5}, page_content='Jupiter, Saturn, Uranus, Neptune, and Pluto are the 5 outer planets.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 6}, page_content='Three quarters of the Earth is covered with water.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 7}, page_content=\"It's a star.\"),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 8}, page_content='It is found beyond Pluto.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 9}, page_content='It is found in the lower part of atmosphere, all of the hydrosphere, and the upper part of the lithosphere.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 10}, page_content=\"It has a thin atmosphere that can't burn up meteors.\"),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 11}, page_content='It is Mercury.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 12}, page_content='It is Mercury.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 13}, page_content='Jupiter, Saturn, Uranus, and Neptune have rings.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 14}, page_content='Jupiter has a small core and has a thick layer of gas around it.'),\n",
       " Document(metadata={'source': '/Users/anurags/Projects/PersonalProjects/book-rag/data/solar-system.json', 'seq_num': 15}, page_content='It is gravity that holds the planets in place.')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(docs[:15])\n",
    "display(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")\n",
    "\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008603463, -0.008584372, -0.15307632]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The meaning of life is 42\"\n",
    "vector = embeddings.embed_query(input_text)\n",
    "print(vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vector_store(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000, chunk_overlap=200)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(\"‚úÖ text splitting done\")\n",
    "\n",
    "    _ = vector_store.add_documents(documents=docs)\n",
    "\n",
    "    print(\"‚úÖ Knowledge base updated successfully!\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ text splitting done\n",
      "‚úÖ Knowledge base updated successfully!\n"
     ]
    }
   ],
   "source": [
    "vector_store = update_vector_store(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Venus is the hottest planet.\n",
      "\n",
      "Document 2:\n",
      "There are 4 planets made of gas.\n",
      "\n",
      "Document 3:\n",
      "It is made of rock and the others are gas planets.\n",
      "\n",
      "Document 4:\n",
      "Jupiter has a small core and has a thick layer of gas around it.\n"
     ]
    }
   ],
   "source": [
    "query = \"Hottest planet\"\n",
    "retrieved_docs = vector_store.similarity_search(query)\n",
    "\n",
    "# Print the first 100 characters of each result\n",
    "for i, doc in enumerate(retrieved_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    # print(doc.page_content[:100] + \"...\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anurags/Library/Caches/pypoetry/virtualenvs/book-rag-o4xYDdTl-py3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anurags/Library/Caches/pypoetry/virtualenvs/book-rag-o4xYDdTl-py3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    question: str\n",
    "    context: Optional[List[Dict]]\n",
    "    answer: str\n",
    "    tenant: str\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "def retrieve(vector_store, state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "def stream(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    for token in llm.stream(messages):\n",
    "        yield token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got the context!!\n",
      "Venus is the hottest planet, with surface temperatures reaching as high as 462¬∞C (863¬∞F). It is composed primarily of rock and metal, unlike the other gas giants in our solar system. Jupiter is not considered the hottest planet.\n"
     ]
    }
   ],
   "source": [
    "state = {'question': \"hottest planet\", 'context': None, 'answer': '', 'tenant': \"solar-system\"}\n",
    "\n",
    "context = retrieve(vector_store, state)\n",
    "print(\"got the context!!\")\n",
    "state['context'] = context['context']\n",
    "\n",
    "print(generate(state)['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got the context!!\n",
      "Venus is the hottest planet, with surface temperatures reaching as high as 462¬∞C (863¬∞F). It's primarily composed of rock and has a thick atmosphere that traps heat. This makes Venus the hottest planet in our solar system."
     ]
    }
   ],
   "source": [
    "state = {'question': \"hottest planet\", 'context': None, 'answer': '', 'tenant': \"solar-system\"}\n",
    "\n",
    "context = retrieve(vector_store, state)\n",
    "print(\"got the context!!\")\n",
    "state['context'] = context['context']\n",
    "\n",
    "for resp in stream(state):\n",
    "    print(resp.content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185 ms ¬± 26.6 ms per loop (mean ¬± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "state = {'question': \"hottest planet\", 'context': None, 'answer': '', 'tenant': \"solar-system\"}\n",
    "\n",
    "context = retrieve(vector_store, state)\n",
    "state['context'] = context['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_function': OllamaEmbeddings(model='nomic-embed-text', base_url=None, client_kwargs={}, mirostat=None, mirostat_eta=None, mirostat_tau=None, num_ctx=None, num_gpu=None, num_thread=None, repeat_last_n=None, repeat_penalty=None, temperature=None, stop=None, tfs_z=None, top_k=None, top_p=None), 'index': <faiss.swigfaiss.IndexFlatL2; proxy of <Swig Object of type 'faiss::IndexFlatL2 *' at 0x103ad5f20> >, 'docstore': <langchain_community.docstore.in_memory.InMemoryDocstore object at 0x103ad5a90>, 'index_to_docstore_id': {0: 'cac0e650-6639-4cb5-b28c-412db1f1b4c9', 1: 'bfeb6dbb-698c-41af-9aa1-4f332459ab93', 2: 'bc1404d7-78f2-4ed6-b6b8-5a0982a35627', 3: 'a344ff14-e4c0-4f5d-819f-e07171104a53', 4: '3f0f3354-8dd2-45c8-97c6-b881f924bf1c', 5: '3a42927c-345f-4c76-9e36-60e136b9f0df', 6: '54a75b6a-0284-4d41-b1be-a944b386f8c5', 7: '1f1e162a-8f40-422e-be10-65293aff5986', 8: '9c2b7a42-e194-4d50-a847-25f655a9ea3b', 9: '12bf1a66-07ff-4541-9c1e-bc7c0d60fb66', 10: '1de389da-9e04-4a1b-81e8-deea56334896', 11: '766f7277-56c6-4df2-8685-bf7aa7a5049c', 12: '336c6503-06c3-4303-8b0e-8df42f2df779', 13: '6a61f643-1a57-40a4-85ff-ebfba67f5ab2', 14: 'b749a56a-0e5f-4c5c-a89b-1c8bd6219d42', 15: '77ed5902-1571-4cec-95e6-d4209a623a25', 16: 'd3030258-f162-4ab2-b4ff-ad327206871e', 17: '331baf13-0347-46a3-b91d-22f4e9d1d920', 18: '707e5228-12ba-4001-b64e-011d66c34366', 19: 'df0616eb-30d6-4c0a-a178-5689de7447cc'}, 'distance_strategy': <DistanceStrategy.EUCLIDEAN_DISTANCE: 'EUCLIDEAN_DISTANCE'>, 'override_relevance_score_fn': None, '_normalize_L2': False}\n"
     ]
    }
   ],
   "source": [
    "print(vector_store.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-rag-o4xYDdTl-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
