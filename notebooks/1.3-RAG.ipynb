{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import weaviate\n",
    "from weaviate.classes.config import Configure\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
    "from langchain_ollama import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '../data'\n",
    "\n",
    "UPLOAD_DIR = \"uploads\"\n",
    "\n",
    "UPLOAD_PATH = os.path.join(DATA_DIR, UPLOAD_DIR)\n",
    "\n",
    "os.makedirs(UPLOAD_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client = weaviate.connect_to_local()\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.008603463, -0.008584372, -0.15307632]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"The meaning of life is 42\"\n",
    "vector = embeddings.embed_query(input_text)\n",
    "print(vector[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_db = WeaviateVectorStore(\n",
    "    client=weaviate_client,\n",
    "    index_name=\"LangChain_0b0b3243518a4c268131915f0ebe04cb\",\n",
    "    text_key='text',\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anurags/Library/Caches/pypoetry/virtualenvs/book-rag-o4xYDdTl-py3.12/lib/python3.12/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "class State(BaseModel):\n",
    "    question: str\n",
    "    context: Optional[List[Dict]]\n",
    "    answer: str\n",
    "    tenant: str\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2:3b\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "def retrieve(db, state: State):\n",
    "    retrieved_docs = db.similarity_search(state[\"question\"], tenant=state['tenant'])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Venus is the hottest planet.\n",
      "\n",
      "Document 2:\n",
      "There are 4 planets made of gas.\n",
      "\n",
      "Document 3:\n",
      "It is made of rock and the others are gas planets.\n",
      "\n",
      "Document 4:\n",
      "Jupiter has a small core and has a thick layer of gas around it.\n"
     ]
    }
   ],
   "source": [
    "state = {'question': \"hottest planet\", 'context': None, 'answer': '', 'tenant': \"solar-system\"}\n",
    "\n",
    "context = retrieve(vec_db, state)\n",
    "state['context'] = context['context']\n",
    "\n",
    "# Print the first 100 characters of each result\n",
    "for i, doc in enumerate(context['context']):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    # print(doc.page_content[:100] + \"...\")\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Venus is the hottest planet, with surface temperatures reaching as high as 462°C (863°F). It is composed primarily of rock and metal, unlike the other gas giants in our solar system. Jupiter is not considered the hottest planet.\n"
     ]
    }
   ],
   "source": [
    "print(generate(state)['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199 ms ± 39.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "state = {'question': \"hottest planet\", 'context': None, 'answer': '', 'tenant': \"solar-system\"}\n",
    "\n",
    "context = retrieve(vec_db, state)\n",
    "state['context'] = context['context']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks Vector Stores\n",
    "### FAISS\n",
    "- 179 ms ± 26.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "- 185 ms ± 26.6 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "\n",
    "### Weaviate (Docker)\n",
    "- 500 ms ± 263 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "- 1.2 s ± 693 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "- 1.13 s ± 265 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "- 170 ms ± 25.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
    "- 199 ms ± 39.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "book-rag-o4xYDdTl-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
